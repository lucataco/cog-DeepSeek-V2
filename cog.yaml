# Configuration for Cog ⚙️
# Reference: https://cog.run/yaml

build:
  gpu: true
  cuda: "12.1"
  system_packages:
    - cmake
  python_version: "3.11"
  python_packages:
    - "aiohttp[speedups]"
    - "packaging"
    - "ninja"

  run:
    - pip install https://r2.drysys.workers.dev/tmp/cog-0.10.0a6-py3-none-any.whl
    - CUDA_SELECT_NVCC_ARCH_FLAGS="8.0;8.6;8.9;9.0" TORCH_CUDA_ARCH_LIST="8.0;8.6;8.9;9.0" CUDA_ARCH_LIST="8.0;8.6;8.9;9.0" CUDA_HOME=/usr/local/cuda mount=type=cache,target=/root/.cache/pip pip install --ignore-installed git+https://github.com/vllm-project/vllm.git@refs/pull/4560/head
    - curl -o /usr/local/bin/pget -L "https://github.com/replicate/pget/releases/download/v0.5.6/pget_linux_x86_64" && chmod +x /usr/local/bin/pget
    - bash -c 'ln -s /usr/local/lib/python3.11/site-packages/torch/lib/lib{nv,cu}* /usr/lib'
# predict.py defines how predictions are run on your model
predict: "predict.py:Predictor"